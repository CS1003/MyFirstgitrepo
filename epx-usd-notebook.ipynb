{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12841620,"sourceType":"datasetVersion","datasetId":8121815}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PREDICTING EPX/USD: A Deep Learning Approach to Cryptocurrency Forecasting","metadata":{}},{"cell_type":"markdown","source":"\n### INTRODUCTION ###\n\nCryptocurrencies continue to attract attention from traders, analysts, and researchers alike due to their high volatility and growth potential. One such emerging digital asset is EPX (Ellipsis), typically traded against the US Dollar (EPX/USD). Like most crypto pairs, EPX/USD experiences significant price fluctuations, influenced by market demand, liquidity, and broader macroeconomic trends.\n\nAccurate price prediction in such a volatile market can help traders make informed decisions, identify entry and exit points, and minimize risks. In this blog, we explore the use of Gated Recurrent Unit (GRU) networks—a deep learning model well-suited for sequential data—to forecast EPX/USD movements.","metadata":{}},{"cell_type":"code","source":"# Importing necessary libraries\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL']= '-1'\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GRU,Dense,Dropout,Input\n\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n\nimport warnings\nwarnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n\nfrom absl import logging\nlogging.set_verbosity(logging.ERROR)\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport tensorflow as tf\nimport random\n\n#Setting seeds to get a consistent output\nSEED=42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T07:19:57.257908Z","iopub.execute_input":"2025-09-07T07:19:57.258257Z","iopub.status.idle":"2025-09-07T07:19:57.278763Z","shell.execute_reply.started":"2025-09-07T07:19:57.258232Z","shell.execute_reply":"2025-09-07T07:19:57.277395Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/epxusdt-analysis/EPX_USD Binance Historical Data.csv\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":" **EPX/USD Dataset**\n\nThe first few rows of a dataset gives us an understanding of its structure and contents. The columns include:\n\nDate: The date of the trading record.\n\nPrice: The closing price at the end of the trading day.\n\nOpen: The opening price at the start of the trading day.\n\nHigh: The highest price reached during the trading day.\n\nLow: The lowest price reached during the trading day.\n\nVol.: The total trading volume for the day.\n\nChange %: The percentage change in price from the previous trading day.","metadata":{}},{"cell_type":"code","source":"# Reading and displaying the first fews rows of the dataset\n\nfile_path = '/kaggle/input/epxusdt-analysis/EPX_USD Binance Historical Data.csv'\ndf = pd.read_csv(file_path)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:44:59.134485Z","iopub.execute_input":"2025-09-07T06:44:59.134853Z","iopub.status.idle":"2025-09-07T06:44:59.154111Z","shell.execute_reply.started":"2025-09-07T06:44:59.134828Z","shell.execute_reply":"2025-09-07T06:44:59.152726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Summary statistics of the numerical coloumns\ndf.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:45:04.205312Z","iopub.execute_input":"2025-09-07T06:45:04.205806Z","iopub.status.idle":"2025-09-07T06:45:04.227781Z","shell.execute_reply.started":"2025-09-07T06:45:04.205778Z","shell.execute_reply":"2025-09-07T06:45:04.226607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking the dataset for missing values\ndf.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:45:05.609803Z","iopub.execute_input":"2025-09-07T06:45:05.611198Z","iopub.status.idle":"2025-09-07T06:45:05.620100Z","shell.execute_reply.started":"2025-09-07T06:45:05.611161Z","shell.execute_reply":"2025-09-07T06:45:05.618958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sorting and setting index\nfile_path = '/kaggle/input/epxusdt-analysis/EPX_USD Binance Historical Data.csv'\ndf = pd.read_csv(file_path,parse_dates = [\"Date\"],header=0)\ndf =df.sort_values(\"Date\")\ndf = df.set_index(\"Date\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:53:58.623452Z","iopub.execute_input":"2025-09-07T06:53:58.625040Z","iopub.status.idle":"2025-09-07T06:53:58.643367Z","shell.execute_reply.started":"2025-09-07T06:53:58.624993Z","shell.execute_reply":"2025-09-07T06:53:58.642025Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Indicators: Support and Resistance**\n\nIn addition to raw price data, technical indicators like support and resistance levels provide valuable context.\n\nSupport: A price level where buying pressure tends to outweigh selling pressure, preventing further decline.\n\nResistance: A price level where selling pressure typically exceeds buying pressure, preventing further rise.\n","metadata":{}},{"cell_type":"code","source":"# Creating new coloumns in dataset for support and resistance indicators\n\nsupport_w=20\nresist_w=20\ndf[\"Support\"] = df[\"Price\"].rolling(window=support_w,min_periods=support_w).min()\ndf[\"Resistance\"] = df[\"Price\"].rolling(window=resist_w,min_periods=resist_w).max()\n\n\n# Distance from support and Resistance lines\n\ndf[\"Dist_to_Support\"] = df[\"Price\"] - df[\"Support\"]\n\ndf[\"Dist_to_Resistance\"] = df[\"Resistance\"]-df[\"Price\"]\n\ndf=df.dropna()\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:54:54.304401Z","iopub.execute_input":"2025-09-07T06:54:54.304763Z","iopub.status.idle":"2025-09-07T06:54:54.332551Z","shell.execute_reply.started":"2025-09-07T06:54:54.304739Z","shell.execute_reply":"2025-09-07T06:54:54.331484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Selection of Features and Target\nfeature_cols=[\"Price\",\"Support\",\"Resistance\",\"Dist_to_Support\",\"Dist_to_Resistance\"]\ntarget_col = [\"Price\"]\n\nfeatures = df[feature_cols].copy()\ntarget = df[target_col].copy()\nstart_date = pd.DataFrame()\n\nstart_date[\"Date\"] = df.index\ndate_col = start_date[\"Date\"]\n#print(date_col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:45:25.327260Z","iopub.execute_input":"2025-09-07T06:45:25.328394Z","iopub.status.idle":"2025-09-07T06:45:25.341815Z","shell.execute_reply.started":"2025-09-07T06:45:25.328353Z","shell.execute_reply":"2025-09-07T06:45:25.340520Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Splitting Data into Training set,Validation set and Test set\n\nn=len(df)\ntrain_end=int(n*.7)\nval_end=int(n*.85)\n\nX_train_raw = features.iloc[:train_end]\ny_train_raw= target.iloc[:train_end]\n\nX_val_raw = features.iloc[train_end:val_end]\ny_val_raw = target.iloc[train_end:val_end]\n\nX_test_raw=features.iloc[val_end:]\ny_test_raw = target.iloc[val_end:]\ndate_index = date_col.iloc[val_end:] \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:45:31.845226Z","iopub.execute_input":"2025-09-07T06:45:31.845924Z","iopub.status.idle":"2025-09-07T06:45:31.853281Z","shell.execute_reply.started":"2025-09-07T06:45:31.845894Z","shell.execute_reply":"2025-09-07T06:45:31.851993Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"  \n **Data Preprocessing**\n\nWhen working with machine learning models, it’s important to ensure that features are on a comparable scale. Many algorithms (like gradient descent, k-means, and neural networks) perform better when numeric values are normalized.\nMinMaxScaler from scikit-learn is one of the most popular normalization techniques. It transforms each feature individually by scaling its values into a fixed range, usually [0, 1].\n\nThe fit_transform() method is used during preprocessing to both:\n\n1.Learn the parameters from the training data.\n\n2.Apply the learned scaling to the data.","metadata":{}},{"cell_type":"code","source":"# Preprocessing of sets\n\nfeat_scaler = MinMaxScaler()\ntgt_scaler = MinMaxScaler()\n\nX_train_raw = np.array(X_train_raw)\nX_val_raw = np.array(X_val_raw)\nX_test_raw = np.array(X_test_raw)\n\nX_train_scaled = feat_scaler.fit_transform(X_train_raw)\nX_val_scaled = feat_scaler.transform(X_val_raw)\nX_test_scaled = feat_scaler.transform(X_test_raw)\n\ny_train_raw = np.array(y_train_raw).reshape(-1,1)\ny_val_raw = np.array(y_val_raw).reshape(-1,1)\ny_test_raw = np.array(y_test_raw).reshape(-1,1)\n\n\ny_train_scaled = tgt_scaler.fit_transform(y_train_raw)\ny_val_scaled= tgt_scaler.transform(y_val_raw)\ny_test_scaled = tgt_scaler.transform(y_test_raw)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:45:42.361884Z","iopub.execute_input":"2025-09-07T06:45:42.362211Z","iopub.status.idle":"2025-09-07T06:45:42.373845Z","shell.execute_reply.started":"2025-09-07T06:45:42.362188Z","shell.execute_reply":"2025-09-07T06:45:42.372683Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating a function for making sequences\n\ndef make_sequences(X2D,y2D,lookback):\n    X_list,y_list=[],[]\n    for i in range(lookback,len(X2D)):\n         X_list.append(X2D[i-lookback:i,:])\n         y_list.append(y2D[i,0])\n    return np.array(X_list),np.array(y_list)\n\nlookback=74\n\nX_train,y_train = make_sequences(X_train_scaled,y_train_scaled,lookback)\n\nX_val,y_val = make_sequences(X_val_scaled,y_val_scaled,lookback)\n\nX_test,y_test = make_sequences(X_test_scaled,y_test_scaled,lookback)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:45:47.678704Z","iopub.execute_input":"2025-09-07T06:45:47.679795Z","iopub.status.idle":"2025-09-07T06:45:47.688243Z","shell.execute_reply.started":"2025-09-07T06:45:47.679758Z","shell.execute_reply":"2025-09-07T06:45:47.687069Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**GRU Model for Cryptocurrency Prediction**\n\nTime-series forecasting, such as predicting cryptocurrency prices, requires models that can capture temporal dependencies in historical data. Traditional machine learning models (like linear regression or random forests) often fail to handle the sequential nature of price data effectively.\n\nThis is where Recurrent Neural Networks (RNNs) come into play. Among RNN architectures, GRU (Gated Recurrent Unit) and LSTM (Long Short-Term Memory) are widely used. \n\nTime series often involve both short-term patterns (daily/weekly) and long-term trends (monthly/seasonal).GRU captures Long-Term dependencies well enough.\nWhile LSTM was designed to handle long-term dependencies, GRU achieves similar performance without the extra complexity.\n\nGRUs capture short-term dependencies well, and with proper training + hyperparameter tuning, they can also capture medium/long-term dependencies.\n\nBecause GRUs have fewer parameters, they tend to generalize better on smaller datasets—which is common in financial/stock/cryptocurrency time series.\n\n","metadata":{}},{"cell_type":"code","source":"# GRU model\nimport warnings\nwarnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL']= '-1'\n\nlookback=74\nmodel=Sequential([\n                  Input(shape=(lookback,X_train.shape[2])),\n                  GRU(64,return_sequences=True),\n                  Dropout(0.2),\n                  GRU(64),\n                  Dropout(0.2),\n                  Dense(1)])\n\nmodel.compile(optimizer=\"adam\",loss = \"mse\")\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:46:58.047168Z","iopub.execute_input":"2025-09-07T06:46:58.047470Z","iopub.status.idle":"2025-09-07T06:46:58.134203Z","shell.execute_reply.started":"2025-09-07T06:46:58.047449Z","shell.execute_reply":"2025-09-07T06:46:58.132818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training \n\nes = EarlyStopping(monitor=\"val_loss\",patience = 8,restore_best_weights=True)\nckpt= ModelCheckpoint(\"best_gru_sr.keras\",monitor = \"val_loss\",save_best_only = True)\n\nhistory = model.fit(X_train,y_train,validation_data = (X_val,y_val),epochs=100,batch_size=32,callbacks = [es,ckpt],verbose =1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:47:08.582443Z","iopub.execute_input":"2025-09-07T06:47:08.582849Z","iopub.status.idle":"2025-09-07T06:48:13.334509Z","shell.execute_reply.started":"2025-09-07T06:47:08.582825Z","shell.execute_reply":"2025-09-07T06:48:13.333024Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Performance Metrics**\n\nMean Absolute Error (MAE)\nThe average of the absolute differences between predicted and actual values.\nIt tells you how far off your predictions are, on average, in the same units as your data.\n\nRoot Mean Squared Error (RMSE)\nThe square root of the average of squared differences between predicted and actual values.Like MAE, but gives more weight to larger errors.\n\nAccuracy Insights\nLower MAE and RMSE = better predictive accuracy.\n","metadata":{}},{"cell_type":"code","source":"# Evaluation on test set\n\nimport warnings\nwarnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n\ny_test_pred_scaled = model.predict(X_test)\ny_test_pred = tgt_scaler.transform(y_test_raw[lookback:].reshape(-1,1))*0\ny_test_pred = tgt_scaler.inverse_transform(y_test_pred_scaled)\n\nactual_test=pd.DataFrame()\n\n#Align actuals to the same indices used for sequences\nx= y_test_raw[lookback:].copy()\nx = pd.DataFrame(x)\nd= date_index.iloc[lookback:].copy()\n\nactual_test =  x \n\ny_testpred = y_test_pred.copy()\ny_testpred =pd.DataFrame(y_testpred)\n\nactual_test.loc[:,\"Pred\"] = y_testpred\nactual_test.loc[:,\"Target_col\"]= actual_test[0] \nactual_test.loc[:,'Date'] = d.values\nactual_test = actual_test.set_index(\"Date\")\n\nmae = mean_absolute_error(actual_test[\"Target_col\"],actual_test[\"Pred\"])\nrmse = mean_squared_error(actual_test[\"Target_col\"],actual_test[\"Pred\"],squared = False)\nprint(f\"Test MAE:{mae:.6f}|Test RMSE:{rmse:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:48:51.264398Z","iopub.execute_input":"2025-09-07T06:48:51.264877Z","iopub.status.idle":"2025-09-07T06:48:52.540503Z","shell.execute_reply.started":"2025-09-07T06:48:51.264851Z","shell.execute_reply":"2025-09-07T06:48:52.539399Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prediction for the next day\n\n# Take the last \"lookback\" steps from the full scaled feature set\n\nfull_scaled = feat_scaler.transform(features.values)\nlast_seq = full_scaled[-lookback:,:].reshape(1,lookback,full_scaled.shape[1])\nnext_scaled=model.predict(last_seq)\nnext_close = tgt_scaler.inverse_transform(next_scaled)[0,0]\nprint(f\"Next-day predicted close:{next_close:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:49:01.008875Z","iopub.execute_input":"2025-09-07T06:49:01.009211Z","iopub.status.idle":"2025-09-07T06:49:01.148666Z","shell.execute_reply.started":"2025-09-07T06:49:01.009184Z","shell.execute_reply":"2025-09-07T06:49:01.147673Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting GRU Prediction with Support and Resistance Features\n\ntest_index = actual_test.index\n\n# Convert RangeIndex to DateTimeIndex \nif isinstance(test_index, pd.RangeIndex):\n    test_index = pd.date_range(start='2022-03-06', periods=len(test_index), freq='D')\n    actual_test.index = test_index  # Update index so plots align\n\n# Plot actual vs predicted close prices\nplt.figure(figsize=(12, 6))\nplt.plot(test_index, actual_test[\"Target_col\"].values, label=\"Actual Close\")\nplt.plot(test_index, actual_test[\"Pred\"].values, label=\"Predicted Close\")\n\n# Plot support and resistance\nsr_vis = df.iloc[val_end + lookback: ]  # align to test plot \n\n\nif isinstance(sr_vis.index, pd.RangeIndex):\n    sr_vis.index = pd.date_range(start='2024-03-06', periods=len(sr_vis), freq='D')\n    sr_vis.index = test_index\n\nplt.plot(sr_vis.index, sr_vis[\"Support\"].values, linestyle=\"dashed\", label=\"Support\")\nplt.plot(sr_vis.index, sr_vis[\"Resistance\"].values, linestyle=\"dashed\", label=\"Resistance\")\n\n# Final plot settings\nplt.title(\"GRU Prediction with Support and Resistance Features\")\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:49:05.942020Z","iopub.execute_input":"2025-09-07T06:49:05.942418Z","iopub.status.idle":"2025-09-07T06:49:06.465201Z","shell.execute_reply.started":"2025-09-07T06:49:05.942369Z","shell.execute_reply":"2025-09-07T06:49:06.464068Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Evaluation Metrics: MAPE and Accuracy**\n\nTo measure how well the GRU model performs, two important metrics are used:\n\nMean Absolute Percentage Error (MAPE)\n\nMAPE measures the average percentage error between predicted and actual values.\n\nA lower MAPE indicates higher accuracy, making it a standard for regression-based forecasting.","metadata":{}},{"cell_type":"markdown","source":"**Accuracy(Regression Adaptation)**\n\nIn regression problems, accuracy can be defined as how close predictions are within a certain threshold of the actual value.\n\nCombining both metrics provides a balanced view: MAPE quantifies overall error, while accuracy indicates practical usefulness in real trading conditions\n\nEstimating Accuracy from MAPE\n\nMAPE (Mean Absolute Percentage Error) is actually a measure of inaccuracy, but you can flip it to get a sense of accuracy too.\n\nEstimating Accuracy\n\nSince MAPE tells you the average percentage error, you can estimate accuracy like this:\n\nEstimated Accuracy (%) = 100% − MAPE (%)\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Calculating accuracy of the prediction using MAPE\n\ndef prediction_accuracy(y_true,y_pred,tolerance=0.05): \n\n    mape = tf.reduce_mean(tf.abs((y_true-y_pred)/y_true))*100\n    print('Value of MAPE',mape)\n    accuracy_percent = 100-mape\n    accuracy_percent = round(accuracy_percent.numpy(),2)\n    return accuracy_percent\n\naccuracy = prediction_accuracy(actual_test[\"Target_col\"],actual_test[\"Pred\"])\n\nprint('Accuracy of prediction in percentage:',accuracy) \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T06:49:25.925328Z","iopub.execute_input":"2025-09-07T06:49:25.925794Z","iopub.status.idle":"2025-09-07T06:49:25.945277Z","shell.execute_reply.started":"2025-09-07T06:49:25.925769Z","shell.execute_reply":"2025-09-07T06:49:25.942304Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Conclusion**\n\nPredicting cryptocurrency prices like EPX/USD is inherently challenging due to volatility and external market influences. However, with advanced deep learning techniques such as GRU and enriched with support/resistance indicators, we can build models that provide valuable insights.\n\nBy evaluating results through MAPE and accuracy, traders and researchers can better assess the reliability of forecasts and incorporate them into decision-making.\n\nIn the fast-paced world of crypto trading, such predictive models don’t guarantee profits—but they do offer a data-driven edge in navigating uncertainty.","metadata":{}}]}